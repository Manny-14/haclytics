{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Process training data in chronological order\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Calculate stats using only past data\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     team_stats \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_rolling_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Get matches for current date\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     current_matches \u001b[38;5;241m=\u001b[39m train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m date]\n",
      "Cell \u001b[0;32mIn[2], line 42\u001b[0m, in \u001b[0;36mcalculate_rolling_stats\u001b[0;34m(data, date)\u001b[0m\n\u001b[1;32m     38\u001b[0m team_stats \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m team \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Get past home games\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     home_games \u001b[38;5;241m=\u001b[39m \u001b[43mpast_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpast_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mteam\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtail\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     away_games \u001b[38;5;241m=\u001b[39m past_data[past_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m team]\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Calculate average goals\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/haclytics/.venv/lib/python3.12/site-packages/pandas/core/generic.py:5974\u001b[0m, in \u001b[0;36mNDFrame.tail\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   5972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 5974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/haclytics/.venv/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/haclytics/.venv/lib/python3.12/site-packages/pandas/core/indexing.py:1729\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame indexer is not allowed for .iloc\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using .loc for automatic alignment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1726\u001b[0m     )\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m-> 1729\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_slice_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   1732\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n",
      "File \u001b[0;32m~/Documents/haclytics/.venv/lib/python3.12/site-packages/pandas/core/indexing.py:1765\u001b[0m, in \u001b[0;36m_iLocIndexer._get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1763\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1764\u001b[0m labels\u001b[38;5;241m.\u001b[39m_validate_positional_slice(slice_obj)\n\u001b[0;32m-> 1765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/haclytics/.venv/lib/python3.12/site-packages/pandas/core/generic.py:4369\u001b[0m, in \u001b[0;36mNDFrame._slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   4367\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(slobj, \u001b[38;5;28mslice\u001b[39m), \u001b[38;5;28mtype\u001b[39m(slobj)\n\u001b[1;32m   4368\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis)\n\u001b[0;32m-> 4369\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4370\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_mgr, axes\u001b[38;5;241m=\u001b[39mnew_mgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   4371\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32minternals.pyx:871\u001b[0m, in \u001b[0;36mpandas._libs.internals.BlockManager.get_slice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32minternals.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.internals.BlockManager._slice_mgr_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32minternals.pyx:704\u001b[0m, in \u001b[0;36mpandas._libs.internals.Block.slice_block_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32minternals.pyx:704\u001b[0m, in \u001b[0;36mpandas._libs.internals.Block.slice_block_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32minternals.pyx:710\u001b[0m, in \u001b[0;36mpandas._libs.internals.Block.slice_block_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/haclytics/.venv/lib/python3.12/site-packages/pandas/core/arrays/datetimelike.py:381\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03mThis getitem defers to the underlying array, which by-definition can\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03monly handle list-likes, slices, and integer scalars\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Use cast as we know we will get back a DatetimeLikeArray or DTScalar,\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# but skip evaluating the Union at runtime for performance\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# (see https://github.com/pandas-dev/pandas/pull/44624)\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m result \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnion[Self, DTScalarOrNaT]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_scalar(result):\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/haclytics/.venv/lib/python3.12/site-packages/pandas/core/arrays/_mixins.py:282\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     key: PositionalIndexer2D,\n\u001b[1;32m    281\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self \u001b[38;5;241m|\u001b[39m Any:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;66;03m# fast-path\u001b[39;00m\n\u001b[1;32m    284\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndarray[key]\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def get_result(row):\n",
    "    if row['gh'] > row['ga']:\n",
    "        return 'home_win'\n",
    "    elif row['gh'] < row['ga']:\n",
    "        return 'away_win'\n",
    "    else:\n",
    "        return 'draw'\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_parquet('games.parquet')\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df = df[df['date'] >= '2000-01-01']\n",
    "\n",
    "# Basic filtering (as in original code)\n",
    "top_leagues = ['england', 'spain', 'italy', 'germany', 'france']\n",
    "uefa_comp = ['UEFA EL', 'UEFA CL', 'UEFA CONF L']\n",
    "condition_domestic = df['competition'].str.lower().isin(top_leagues)\n",
    "condition_uefa = df['competition'].str.upper().isin(uefa_comp)\n",
    "df_filtered = df[condition_domestic | condition_uefa]\n",
    "df_filtered = df_filtered.sort_values(by='date')\n",
    "\n",
    "# Create target variable\n",
    "df_filtered['match_result'] = df_filtered.apply(get_result, axis=1)\n",
    "\n",
    "# Feature engineering with proper time-based splits\n",
    "def calculate_rolling_stats(data, date):\n",
    "    \"\"\"Calculate rolling statistics using only past data\"\"\"\n",
    "    past_data = data[data['date'] < date].copy()\n",
    "    \n",
    "    # Calculate team performance metrics\n",
    "    team_stats = {}\n",
    "    \n",
    "    for team in data['home'].unique():\n",
    "        # Get past home games\n",
    "        home_games = past_data[past_data['home'] == team].tail(5)\n",
    "        away_games = past_data[past_data['away'] == team].tail(5)\n",
    "        \n",
    "        # Calculate average goals\n",
    "        avg_goals_scored = (home_games['gh'].mean() + away_games['ga'].mean()) / 2\n",
    "        avg_goals_conceded = (home_games['ga'].mean() + away_games['gh'].mean()) / 2\n",
    "        \n",
    "        # Calculate win rate\n",
    "        home_wins = (home_games['gh'] > home_games['ga']).mean()\n",
    "        away_wins = (away_games['ga'] > away_games['gh']).mean()\n",
    "        win_rate = (home_wins + away_wins) / 2\n",
    "        \n",
    "        team_stats[team] = {\n",
    "            'avg_goals_scored': avg_goals_scored,\n",
    "            'avg_goals_conceded': avg_goals_conceded,\n",
    "            'win_rate': win_rate\n",
    "        }\n",
    "    \n",
    "    return team_stats\n",
    "\n",
    "def prepare_features(df, team_stats):\n",
    "    \"\"\"Prepare features for a single match\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Add team performance metrics\n",
    "    for index, row in df.iterrows():\n",
    "        home_team = row['home']\n",
    "        away_team = row['away']\n",
    "        \n",
    "        if home_team in team_stats and away_team in team_stats:\n",
    "            features.loc[index, 'home_avg_goals'] = team_stats[home_team]['avg_goals_scored']\n",
    "            features.loc[index, 'home_avg_conceded'] = team_stats[home_team]['avg_goals_conceded']\n",
    "            features.loc[index, 'home_win_rate'] = team_stats[home_team]['win_rate']\n",
    "            \n",
    "            features.loc[index, 'away_avg_goals'] = team_stats[away_team]['avg_goals_scored']\n",
    "            features.loc[index, 'away_avg_conceded'] = team_stats[away_team]['avg_goals_conceded']\n",
    "            features.loc[index, 'away_win_rate'] = team_stats[away_team]['win_rate']\n",
    "    \n",
    "    # Add competition features\n",
    "    features = pd.concat([features, pd.get_dummies(df['competition'], prefix='comp')], axis=1)\n",
    "    \n",
    "    # Add month feature (seasonality)\n",
    "    features['month'] = df['date'].dt.month\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Split data chronologically\n",
    "train_date = df_filtered['date'].quantile(0.8)\n",
    "train_df = df_filtered[df_filtered['date'] <= train_date]\n",
    "test_df = df_filtered[df_filtered['date'] > train_date]\n",
    "\n",
    "# Prepare features for training data\n",
    "X_train = pd.DataFrame()\n",
    "y_train = []\n",
    "\n",
    "# Process training data in chronological order\n",
    "for date in sorted(train_df['date'].unique()):\n",
    "    # Calculate stats using only past data\n",
    "    team_stats = calculate_rolling_stats(train_df, date)\n",
    "    \n",
    "    # Get matches for current date\n",
    "    current_matches = train_df[train_df['date'] == date]\n",
    "    \n",
    "    # Prepare features\n",
    "    current_features = prepare_features(current_matches, team_stats)\n",
    "    \n",
    "    if not current_features.empty:\n",
    "        X_train = pd.concat([X_train, current_features])\n",
    "        y_train.extend(current_matches['match_result'].tolist())\n",
    "\n",
    "# Prepare features for test data\n",
    "X_test = pd.DataFrame()\n",
    "y_test = []\n",
    "\n",
    "# Process test data using only training data for statistics\n",
    "for date in sorted(test_df['date'].unique()):\n",
    "    team_stats = calculate_rolling_stats(train_df, date)  # Use only training data\n",
    "    current_matches = test_df[test_df['date'] == date]\n",
    "    current_features = prepare_features(current_matches, team_stats)\n",
    "    \n",
    "    if not current_features.empty:\n",
    "        X_test = pd.concat([X_test, current_features])\n",
    "        y_test.extend(current_matches['match_result'].tolist())\n",
    "\n",
    "# Handle missing values\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Scale numeric features\n",
    "numeric_features = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
